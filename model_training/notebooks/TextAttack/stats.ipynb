{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1de3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "→ Average number of word changes per example: 33.91\n",
      "\n",
      "→ Top 10 replacement pairs (orig → new):\n",
      "Count | Original → New\n",
      "------------------------------\n",
      "  293 | said → aforesaid\n",
      "  261 | said → stated\n",
      "  239 | The → Both\n",
      "  177 | I → me\n",
      "  173 | know → recognise\n",
      "  162 | new → novel\n",
      "  162 | The → Per\n",
      "  154 | said. → aforesaid.\n",
      "  149 | The → he\n",
      "  148 | said → enunciate\n",
      "\n",
      "→ POS distribution of replaced (original) words:\n",
      "Count | POS tag\n",
      "-------------------------\n",
      "57589 | NN\n",
      "42459 | NNP\n",
      "34030 | JJ\n",
      "17049 | NNS\n",
      "14758 | VBD\n",
      "10966 | VBG\n",
      "10542 | RB\n",
      " 9604 | VBP\n",
      " 6153 | VBN\n",
      " 5391 | VB\n",
      " 4606 | VBZ\n",
      " 4222 | IN\n",
      " 4156 | CD\n",
      " 2025 | PRP\n",
      " 1855 | DT\n",
      " 1413 | MD\n",
      "  779 | JJS\n",
      "  569 | JJR\n",
      "  490 | NNPS\n",
      "  396 | POS\n",
      "  327 | RBR\n",
      "  316 | CC\n",
      "  231 | PRP$\n",
      "  154 | FW\n",
      "  148 | RP\n",
      "  123 | TO\n",
      "  122 | WRB\n",
      "  118 | WP\n",
      "   50 | EX\n",
      "   35 | WDT\n",
      "   34 | WP$\n",
      "   22 | RBS\n",
      "   17 | ''\n",
      "   13 | PDT\n",
      "   11 | $\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "# === Configurațiile căilor ===\n",
    "files = [\n",
    "    \"textFooler/textfooler_results_all.csv\",\n",
    "    \"PWWS/pwws_results_all.csv\",\n",
    "    \"textBugger/textbugger_results_all.csv\",\n",
    "]\n",
    "\n",
    "# 1) Încarcă și concatenează\n",
    "dfs = []\n",
    "for path in files:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Nu am găsit fișierul: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    dfs.append(df)\n",
    "results = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 2) Păstrează doar succesele\n",
    "results = results[results[\"result_type\"] == \"Successful\"].copy()\n",
    "\n",
    "# 3) Curăță marcajele [[…]]\n",
    "def clean_markers(text):\n",
    "    return re.sub(r\"\\[\\[(.*?)\\]\\]\", r\"\\1\", text)\n",
    "\n",
    "results[\"orig_clean\"] = results[\"original_text\"].apply(clean_markers)\n",
    "results[\"pert_clean\"] = results[\"perturbed_text\"].apply(clean_markers)\n",
    "\n",
    "# 4) Funcție care extrage perechi de cuvinte înlocuite\n",
    "def diff_pairs(orig, pert):\n",
    "    o, p = orig.split(), pert.split()\n",
    "    diff = list(difflib.ndiff(o, p))\n",
    "    pairs = []\n",
    "    i = 0\n",
    "    while i < len(diff):\n",
    "        if diff[i].startswith(\"- \"):\n",
    "            o_word = diff[i][2:]\n",
    "            # găsește următoarea adăugare\n",
    "            j = i + 1\n",
    "            while j < len(diff) and not diff[j].startswith(\"+ \"):\n",
    "                j += 1\n",
    "            if j < len(diff):\n",
    "                p_word = diff[j][2:]\n",
    "                pairs.append((o_word, p_word))\n",
    "                i = j\n",
    "        i += 1\n",
    "    return pairs\n",
    "\n",
    "results[\"diff_pairs\"] = results.apply(\n",
    "    lambda row: diff_pairs(row[\"orig_clean\"], row[\"pert_clean\"]), axis=1\n",
    ")\n",
    "results[\"num_changes\"] = results[\"diff_pairs\"].apply(len)\n",
    "\n",
    "# 5) Statistici\n",
    "#   a) medie de schimbări per exemplu\n",
    "avg_changes = results[\"num_changes\"].mean()\n",
    "\n",
    "#   b) top 10 perechi de înlocuire\n",
    "all_pairs = [pr for sub in results[\"diff_pairs\"] for pr in sub]\n",
    "top10 = Counter(all_pairs).most_common(10)\n",
    "\n",
    "#   c) distribuție POS pentru cuvintele originale\n",
    "orig_words = [o for o,_ in all_pairs]\n",
    "# Asigură-te că ai descărcat tagger-ul anterior:\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "pos_tags = nltk.pos_tag(orig_words)\n",
    "pos_counts = Counter(tag for _, tag in pos_tags).most_common()\n",
    "\n",
    "# 6) Afișează rezultatele\n",
    "print(f\"\\n→ Average number of word changes per example: {avg_changes:.2f}\\n\")\n",
    "\n",
    "print(\"→ Top 10 replacement pairs (orig → new):\")\n",
    "print(\"Count | Original → New\")\n",
    "print(\"-\"*30)\n",
    "for (o,p),cnt in top10:\n",
    "    print(f\"{cnt:5d} | {o} → {p}\")\n",
    "print()\n",
    "\n",
    "print(\"→ POS distribution of replaced (original) words:\")\n",
    "print(\"Count | POS tag\")\n",
    "print(\"-\"*25)\n",
    "for tag, cnt in pos_counts:\n",
    "    print(f\"{cnt:5d} | {tag}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proiect_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
