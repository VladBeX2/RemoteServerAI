{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1de3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â†’ Average number of word changes per example: 33.91\n",
      "\n",
      "â†’ Top 10 replacement pairs (orig â†’ new):\n",
      "Count | Original â†’ New\n",
      "------------------------------\n",
      "  293 | said â†’ aforesaid\n",
      "  261 | said â†’ stated\n",
      "  239 | The â†’ Both\n",
      "  177 | I â†’ me\n",
      "  173 | know â†’ recognise\n",
      "  162 | new â†’ novel\n",
      "  162 | The â†’ Per\n",
      "  154 | said. â†’ aforesaid.\n",
      "  149 | The â†’ he\n",
      "  148 | said â†’ enunciate\n",
      "\n",
      "â†’ POS distribution of replaced (original) words:\n",
      "Count | POS tag\n",
      "-------------------------\n",
      "57589 | NN\n",
      "42459 | NNP\n",
      "34030 | JJ\n",
      "17049 | NNS\n",
      "14758 | VBD\n",
      "10966 | VBG\n",
      "10542 | RB\n",
      " 9604 | VBP\n",
      " 6153 | VBN\n",
      " 5391 | VB\n",
      " 4606 | VBZ\n",
      " 4222 | IN\n",
      " 4156 | CD\n",
      " 2025 | PRP\n",
      " 1855 | DT\n",
      " 1413 | MD\n",
      "  779 | JJS\n",
      "  569 | JJR\n",
      "  490 | NNPS\n",
      "  396 | POS\n",
      "  327 | RBR\n",
      "  316 | CC\n",
      "  231 | PRP$\n",
      "  154 | FW\n",
      "  148 | RP\n",
      "  123 | TO\n",
      "  122 | WRB\n",
      "  118 | WP\n",
      "   50 | EX\n",
      "   35 | WDT\n",
      "   34 | WP$\n",
      "   22 | RBS\n",
      "   17 | ''\n",
      "   13 | PDT\n",
      "   11 | $\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "files = [\n",
    "    \"textFooler/textfooler_results_all.csv\",\n",
    "    \"PWWS/pwws_results_all.csv\",\n",
    "    \"textBugger/textbugger_results_all.csv\",\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for path in files:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Nu am gÄƒsit fiÈ™ierul: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    dfs.append(df)\n",
    "results = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "results = results[results[\"result_type\"] == \"Successful\"].copy()\n",
    "\n",
    "def clean_markers(text):\n",
    "    return re.sub(r\"\\[\\[(.*?)\\]\\]\", r\"\\1\", text)\n",
    "\n",
    "results[\"orig_clean\"] = results[\"original_text\"].apply(clean_markers)\n",
    "results[\"pert_clean\"] = results[\"perturbed_text\"].apply(clean_markers)\n",
    "\n",
    "def diff_pairs(orig, pert):\n",
    "    o, p = orig.split(), pert.split()\n",
    "    diff = list(difflib.ndiff(o, p))\n",
    "    pairs = []\n",
    "    i = 0\n",
    "    while i < len(diff):\n",
    "        if diff[i].startswith(\"- \"):\n",
    "            o_word = diff[i][2:]\n",
    "            j = i + 1\n",
    "            while j < len(diff) and not diff[j].startswith(\"+ \"):\n",
    "                j += 1\n",
    "            if j < len(diff):\n",
    "                p_word = diff[j][2:]\n",
    "                pairs.append((o_word, p_word))\n",
    "                i = j\n",
    "        i += 1\n",
    "    return pairs\n",
    "\n",
    "results[\"diff_pairs\"] = results.apply(\n",
    "    lambda row: diff_pairs(row[\"orig_clean\"], row[\"pert_clean\"]), axis=1\n",
    ")\n",
    "results[\"num_changes\"] = results[\"diff_pairs\"].apply(len)\n",
    "\n",
    "avg_changes = results[\"num_changes\"].mean()\n",
    "\n",
    "all_pairs = [pr for sub in results[\"diff_pairs\"] for pr in sub]\n",
    "top10 = Counter(all_pairs).most_common(10)\n",
    "\n",
    "orig_words = [o for o,_ in all_pairs]\n",
    "pos_tags = nltk.pos_tag(orig_words)\n",
    "pos_counts = Counter(tag for _, tag in pos_tags).most_common()\n",
    "\n",
    "print(f\"\\nâ†’ Average number of word changes per example: {avg_changes:.2f}\\n\")\n",
    "\n",
    "print(\"â†’ Top 10 replacement pairs (orig â†’ new):\")\n",
    "print(\"Count | Original â†’ New\")\n",
    "print(\"-\"*30)\n",
    "for (o,p),cnt in top10:\n",
    "    print(f\"{cnt:5d} | {o} â†’ {p}\")\n",
    "print()\n",
    "\n",
    "print(\"â†’ POS distribution of replaced (original) words:\")\n",
    "print(\"Count | POS tag\")\n",
    "print(\"-\"*25)\n",
    "for tag, cnt in pos_counts:\n",
    "    print(f\"{cnt:5d} | {tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db93c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 substantive Ã®nlocuite È™i Ã®nlocuirile lor frecvente:\n",
      "\n",
      "said ->\n",
      "    293x aforesaid\n",
      "    261x stated\n",
      "    148x enunciate\n",
      "be ->\n",
      "    101x constituted\n",
      "    68x constitute\n",
      "    58x arrive\n",
      "have ->\n",
      "    56x possesses\n",
      "    52x get\n",
      "    46x ai\n",
      "has ->\n",
      "    102x gets\n",
      "    91x possesses\n",
      "    85x had\n",
      "do ->\n",
      "    62x could\n",
      "    50x ai\n",
      "    44x makes\n",
      "made ->\n",
      "    56x realised\n",
      "    33x realise\n",
      "    20x effected\n",
      "think ->\n",
      "    79x reckon\n",
      "    49x visualise\n",
      "    22x thinð’Œ\n",
      "make ->\n",
      "    76x realise\n",
      "    40x fulfil\n",
      "    19x accomplish\n",
      "going ->\n",
      "    19x gonna\n",
      "    15x leaving\n",
      "    14x plump\n",
      "take ->\n",
      "    22x pick\n",
      "    19x involve\n",
      "    17x wear\n",
      "told ->\n",
      "    25x narrate\n",
      "    17x informs\n",
      "    17x say\n",
      "had ->\n",
      "    48x possesses\n",
      "    21x gets\n",
      "    17x ai\n",
      "get ->\n",
      "    24x gets\n",
      "    17x obtain\n",
      "    15x fetch\n",
      "see ->\n",
      "    92x visualise\n",
      "    32x realise\n",
      "    24x reckon\n",
      "know ->\n",
      "    118x recognise\n",
      "    63x realise\n",
      "    6x recognising\n",
      "According ->\n",
      "    38x harmonise\n",
      "    22x concord\n",
      "    19x Depending\n",
      "say ->\n",
      "    13x suppose\n",
      "    12x telling\n",
      "    11x sy\n",
      "seen ->\n",
      "    33x visualise\n",
      "    29x realised\n",
      "    18x sen\n",
      "found ->\n",
      "    12x visualized\n",
      "    10x launch\n",
      "    8x detected\n",
      "making ->\n",
      "    17x framing\n",
      "    17x realise\n",
      "    12x do\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# nltk.download(\"averaged_perceptron_tagger\")  \n",
    "\n",
    "files = [\n",
    "    \"textFooler/textfooler_results_all.csv\",\n",
    "    \"PWWS/pwws_results_all.csv\",\n",
    "    \"textBugger/textbugger_results_all.csv\",\n",
    "]\n",
    "\n",
    "def clean_markers(text):\n",
    "    return re.sub(r\"\\[\\[(.*?)\\]\\]\", r\"\\1\", text)\n",
    "\n",
    "def extract_replacements(orig, pert):\n",
    "    o_tokens = orig.split()\n",
    "    p_tokens = pert.split()\n",
    "    diff = list(difflib.ndiff(o_tokens, p_tokens))\n",
    "    pairs = []\n",
    "    i = 0\n",
    "    while i < len(diff):\n",
    "        if diff[i].startswith(\"- \"):\n",
    "            original = diff[i][2:]\n",
    "            j = i + 1\n",
    "            while j < len(diff) and not diff[j].startswith(\"+ \"):\n",
    "                j += 1\n",
    "            if j < len(diff):\n",
    "                replaced = diff[j][2:]\n",
    "                pairs.append((original, replaced))\n",
    "                i = j\n",
    "        i += 1\n",
    "    return pairs\n",
    "\n",
    "replacement_counter = defaultdict(Counter)\n",
    "\n",
    "for path in files:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Nu gÄƒsesc fiÈ™ierul: {path}\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[df[\"result_type\"] == \"Successful\"]\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        orig = clean_markers(row[\"original_text\"])\n",
    "        pert = clean_markers(row[\"perturbed_text\"])\n",
    "\n",
    "        pairs = extract_replacements(orig, pert)\n",
    "        if not pairs:\n",
    "            continue\n",
    "\n",
    "        orig_words = [orig for orig, _ in pairs]\n",
    "        pos_tags = nltk.pos_tag(orig_words)\n",
    "\n",
    "        for (o_word, p_word), (_, tag) in zip(pairs, pos_tags):\n",
    "            if tag.startswith(\"VB\"):\n",
    "                replacement_counter[o_word][p_word] += 1\n",
    "\n",
    "print(\"\\nTop 10 substantive Ã®nlocuite È™i Ã®nlocuirile lor frecvente:\\n\")\n",
    "for word, repls in Counter({k: sum(v.values()) for k, v in replacement_counter.items()}).most_common(20):\n",
    "    print(f\"{word} ->\")\n",
    "    for rep, cnt in replacement_counter[word].most_common(3):\n",
    "        print(f\"    {cnt}x {rep}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa3b6f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: textFooler/textfooler_results_all.csv\n",
      "Processing: textFooler/val_textfooler_results_all.csv\n",
      "Processing: textFooler/test_textfooler_results_all.csv\n",
      "Processing: PWWS/pwws_results_all.csv\n",
      "Processing: PWWS/val_pwws_results_all.csv\n",
      "Processing: PWWS/test_pwws_results_all.csv\n",
      "Processing: textBugger/textbugger_results_all.csv\n",
      "Processing: textBugger/val_textbugger_results_all.csv\n",
      "Processing: textBugger/test_textbugger_results_all.csv\n",
      "\n",
      "Unique replacements for 'Democrats/democrats':\n",
      "- 208\n",
      "- 2102\n",
      "- 2O15\n",
      "- Ameicans\n",
      "- Assembler\n",
      "- Barack\n",
      "- Chief\n",
      "- Clinton\n",
      "- Como\n",
      "- Congressman\n",
      "- Congresswoman\n",
      "- Conservatism\n",
      "- Democrat\n",
      "- Democrats\n",
      "- Gingrich\n",
      "- However\n",
      "- Msnbc\n",
      "- Nuevo\n",
      "- Obama\n",
      "- Palin\n",
      "- Politico\n",
      "- Presidential\n",
      "- Re\n",
      "- Reelected\n",
      "- Repbulicans\n",
      "- Republican\n",
      "- RepublicanÑ•\n",
      "- Romney\n",
      "- Senate\n",
      "- Senators\n",
      "- Tories\n",
      "- TÕ°is\n",
      "- aiding\n",
      "- appointing\n",
      "- ballot\n",
      "- bulk\n",
      "- businesses\n",
      "- changed\n",
      "- conservative\n",
      "- decide\n",
      "- enquired\n",
      "- integrating\n",
      "- inÑ•ists\n",
      "- legislation\n",
      "- ought\n",
      "- readies\n",
      "- reference\n",
      "- refsal\n",
      "- republican\n",
      "- sei\n",
      "- shared\n",
      "- tendency\n",
      "- usage\n",
      "- vÐ¾cal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "csv_files = [\n",
    "    \"textFooler/textfooler_results_all.csv\",\n",
    "    \"textFooler/val_textfooler_results_all.csv\",\n",
    "    \"textFooler/test_textfooler_results_all.csv\",\n",
    "    \"PWWS/pwws_results_all.csv\",\n",
    "    \"PWWS/val_pwws_results_all.csv\",\n",
    "    \"PWWS/test_pwws_results_all.csv\",\n",
    "    \"textBugger/textbugger_results_all.csv\",\n",
    "    \"textBugger/val_textbugger_results_all.csv\",\n",
    "    \"textBugger/test_textbugger_results_all.csv\"\n",
    "]\n",
    "\n",
    "target_words = {\"republicans\", \"Republicans\"}\n",
    "replacements = set()\n",
    "\n",
    "def extract_marked(text):\n",
    "    return re.findall(r\"\\[\\[(.*?)\\]\\]\", text)\n",
    "\n",
    "for file_path in csv_files:\n",
    "    print(f\"Processing: {file_path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        orig = row.get(\"original_text\", \"\")\n",
    "        pert = row.get(\"perturbed_text\", \"\")\n",
    "        orig_words = extract_marked(orig)\n",
    "        pert_words = extract_marked(pert)\n",
    "\n",
    "        for o, p in zip(orig_words, pert_words):\n",
    "            if o in target_words:\n",
    "                replacements.add(p)\n",
    "\n",
    "print(\"\\nUnique replacements for 'Democrats/democrats':\")\n",
    "for word in sorted(replacements):\n",
    "    print(\"-\", word)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "licenta_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
