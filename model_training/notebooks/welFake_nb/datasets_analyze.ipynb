{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics and wordclouds from datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## WELFAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad.cristescu/miniconda3/envs/proiect_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-03 06:26:05.261870: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import hdbscan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import string\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/WELFake_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72134, 4)\n",
      "(72095, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['clean_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk_texts,gpu_id):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    model = SentenceTransformer('all-mpnet-base-v2',device='cuda')\n",
    "    return model.encode(chunk_texts,batch_size=32,show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 751/751 [02:20<00:00,  5.33it/s]\n",
      "Batches: 100%|██████████| 751/751 [02:21<00:00,  5.32it/s]\n",
      "Batches: 100%|██████████| 751/751 [02:21<00:00,  5.32it/s]\n"
     ]
    }
   ],
   "source": [
    "n_gpus = 3\n",
    "chunks = [texts[i::n_gpus] for i in range(n_gpus)]\n",
    "\n",
    "with mp.Pool(processes=n_gpus) as pool:\n",
    "    results = pool.starmap(process_chunk,[(chunk,i) for i,chunk in enumerate(chunks)])\n",
    "\n",
    "embeddings = np.concatenate(results,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad.cristescu/miniconda3/envs/proiect_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/vlad.cristescu/miniconda3/envs/proiect_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean')\n",
    "cluster_labels = clusterer.fit_predict(embeddings)\n",
    "\n",
    "df['Category'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/WELFake_with_categories.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_cat = pd.read_csv('../datasets/WELFake_with_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "Category\n",
      "-1      62728\n",
      " 1        703\n",
      " 253      334\n",
      " 250      290\n",
      " 237      203\n",
      "        ...  \n",
      " 206       10\n",
      " 52        10\n",
      " 243       10\n",
      " 51        10\n",
      " 131       10\n",
      "Name: count, Length: 258, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print the number of clusters\n",
    "print(df_with_cat['Category'].nunique())\n",
    "print(df_with_cat['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_id in sorted(df_with_cat['Category'].unique()):\n",
    "    texts_cluster = df_with_cat[df_with_cat['Category'] == cluster_id]['text']\n",
    "    combined_text = \" \".join(texts_cluster)\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(combined_text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Cluster {cluster_id}\")\n",
    "    \n",
    "    plt.savefig(f'wordclouds/wordcloud_cluster_{cluster_id}.png', bbox_inches='tight')\n",
    "    plt.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proiect_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
