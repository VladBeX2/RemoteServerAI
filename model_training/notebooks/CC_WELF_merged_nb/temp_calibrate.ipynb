{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 10:25:50.798726: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordopt(text):\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '[URL]', text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../datasets/CC_WELF_merged_cleaned.csv\")\n",
    "df[\"word_count\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
    "df = df[df[\"word_count\"] >= 30]\n",
    "df.drop(columns=[\"word_count\"], inplace=True)\n",
    "df = df[df[\"language\"] == 'en']\n",
    "df[\"text\"] = df[\"text\"].apply(wordopt)\n",
    "\n",
    "texts = df[\"text\"].tolist()\n",
    "labels = df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.encodings = tokenizer(texts,\n",
    "                                   truncation=True,\n",
    "                                   padding=\"max_length\",\n",
    "                                   max_length=max_length,\n",
    "                                   return_tensors=\"pt\")\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: self.encodings[key][idx] for key in self.encodings}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"saved_models/roberta/roberta_tokenizer\")\n",
    "max_length = 512\n",
    "\n",
    "test_dataset = RobertaDataset(test_texts, test_labels, tokenizer, max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_size = int(0.5 * len(test_dataset))\n",
    "evaluation_size = len(test_dataset) - calibration_size\n",
    "calibration_dataset, evaluation_dataset = random_split(test_dataset, [calibration_size, evaluation_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"saved_models/roberta/roberta_torch_model\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemperatureScaler(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TemperatureScaler, self).__init__()\n",
    "        # Folosim log_temperature pentru a garanta T > 0 (T = exp(log_temperature))\n",
    "        self.log_temperature = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self, logits):\n",
    "        temperature = torch.exp(self.log_temperature)\n",
    "        return logits / temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_model(model, calibration_dataset, batch_size=32):\n",
    "    dataloader = DataLoader(calibration_dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            all_logits.append(logits)\n",
    "            all_labels.append(labels)\n",
    "    all_logits = torch.cat(all_logits)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    # Instanțiem modulul de temperature scaling\n",
    "    temp_scaler = TemperatureScaler()\n",
    "    optimizer = optim.LBFGS(temp_scaler.parameters(), lr=0.01, max_iter=50)\n",
    "\n",
    "    def loss_fn():\n",
    "        optimizer.zero_grad()\n",
    "        scaled_logits = temp_scaler(all_logits)\n",
    "        loss = F.cross_entropy(scaled_logits, all_labels)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(loss_fn)\n",
    "    \n",
    "    optimal_temperature = torch.exp(temp_scaler.log_temperature).item()\n",
    "    print(\"Temperatura optimă: {:.4f}\".format(optimal_temperature))\n",
    "    return optimal_temperature, temp_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperatura optimă: 1.1423\n"
     ]
    }
   ],
   "source": [
    "optimal_temp, temp_scaler_module = calibrate_model(model, calibration_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_calibration(model, temp_scaler, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            scaled_logits = temp_scaler(logits)\n",
    "            probs = torch.softmax(scaled_logits, dim=-1)\n",
    "            preds = torch.argmax(probs, dim=-1)\n",
    "            predictions.extend(preds.cpu().numpy().tolist())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(evaluation_dataset, batch_size=32, shuffle=False)\n",
    "predictions = predict_with_calibration(model, temp_scaler_module, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalibratedModel(nn.Module):\n",
    "    def __init__(self, model, temp_scaler):\n",
    "        super(CalibratedModel, self).__init__()\n",
    "        self.model = model          # Modelul RoBERTa deja antrenat\n",
    "        self.temp_scaler = temp_scaler  # Modulul TemperatureScaler calibrat\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Obținem logit-urile din model\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        # Aplicăm temperature scaling pentru a obține logit-uri calibrate\n",
    "        scaled_logits = self.temp_scaler(logits)\n",
    "        # Calculăm probabilitățile calibrate\n",
    "        calibrated_probs = F.softmax(scaled_logits, dim=-1)\n",
    "        return calibrated_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_model = CalibratedModel(model, temp_scaler_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(calibrated_model.state_dict(), \"calibrated_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proiect_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
